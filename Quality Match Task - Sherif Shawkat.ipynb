{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"quality_match.png\" width=\"200\" height=\"200\" align=\"right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Match Task - Sherif Shawkat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_4686</th>\n",
       "      <th>img_8607</th>\n",
       "      <th>img_5541</th>\n",
       "      <th>img_3218</th>\n",
       "      <th>img_3247</th>\n",
       "      <th>img_1876</th>\n",
       "      <th>img_6228</th>\n",
       "      <th>img_4653</th>\n",
       "      <th>img_5488</th>\n",
       "      <th>img_8591</th>\n",
       "      <th>...</th>\n",
       "      <th>img_3563</th>\n",
       "      <th>img_7393</th>\n",
       "      <th>img_7061</th>\n",
       "      <th>img_6877</th>\n",
       "      <th>img_2192</th>\n",
       "      <th>img_5282</th>\n",
       "      <th>img_0628</th>\n",
       "      <th>img_7736</th>\n",
       "      <th>img_1042</th>\n",
       "      <th>img_2866</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_bicycle</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 9087 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            img_4686  img_8607  img_5541  img_3218  img_3247  img_1876  \\\n",
       "is_bicycle     False      True     False     False      True      True   \n",
       "\n",
       "            img_6228  img_4653  img_5488  img_8591  ...  img_3563  img_7393  \\\n",
       "is_bicycle      True     False      True     False  ...      True     False   \n",
       "\n",
       "            img_7061  img_6877  img_2192  img_5282  img_0628  img_7736  \\\n",
       "is_bicycle     False      True      True      True      True      True   \n",
       "\n",
       "            img_1042  img_2866  \n",
       "is_bicycle     False      True  \n",
       "\n",
       "[1 rows x 9087 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the references file\n",
    "references_df = pd.read_json('references.json')\n",
    "references_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>root_node</th>\n",
       "      <td>{'gui_type': 'discrete_answer', 'results': {'7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     results\n",
       "root_node  {'gui_type': 'discrete_answer', 'results': {'7..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the anonymized project file\n",
    "anonymized_df = pd.read_json('anonymized_project.json')\n",
    "anonymized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the anonymized_project.json need some cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-read the anonymized project file\n",
    "f = open('anonymized_project.json')\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gui_type</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000e9703-686d-45c1-9772-9edb38ed2891</th>\n",
       "      <td>discrete_answer</td>\n",
       "      <td>{'results': [{'task_input': {'image_url': 'htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000eac10-afe2-4f3f-b4ed-c79b8cfbdcc1</th>\n",
       "      <td>discrete_answer</td>\n",
       "      <td>{'results': [{'task_input': {'image_url': 'htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0012d625-0d84-4ae9-973f-21acf84eab54</th>\n",
       "      <td>discrete_answer</td>\n",
       "      <td>{'results': [{'task_input': {'image_url': 'htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001460c2-712d-45d2-8afe-cdac237196a2</th>\n",
       "      <td>discrete_answer</td>\n",
       "      <td>{'results': [{'task_input': {'image_url': 'htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001873e5-920a-41e5-9a9c-386412b728b6</th>\n",
       "      <td>discrete_answer</td>\n",
       "      <td>{'results': [{'task_input': {'image_url': 'htt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             gui_type  \\\n",
       "000e9703-686d-45c1-9772-9edb38ed2891  discrete_answer   \n",
       "000eac10-afe2-4f3f-b4ed-c79b8cfbdcc1  discrete_answer   \n",
       "0012d625-0d84-4ae9-973f-21acf84eab54  discrete_answer   \n",
       "001460c2-712d-45d2-8afe-cdac237196a2  discrete_answer   \n",
       "001873e5-920a-41e5-9a9c-386412b728b6  discrete_answer   \n",
       "\n",
       "                                                                                results  \n",
       "000e9703-686d-45c1-9772-9edb38ed2891  {'results': [{'task_input': {'image_url': 'htt...  \n",
       "000eac10-afe2-4f3f-b4ed-c79b8cfbdcc1  {'results': [{'task_input': {'image_url': 'htt...  \n",
       "0012d625-0d84-4ae9-973f-21acf84eab54  {'results': [{'task_input': {'image_url': 'htt...  \n",
       "001460c2-712d-45d2-8afe-cdac237196a2  {'results': [{'task_input': {'image_url': 'htt...  \n",
       "001873e5-920a-41e5-9a9c-386412b728b6  {'results': [{'task_input': {'image_url': 'htt...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_refined = data['results']['root_node']\n",
    "anonymized_df = pd.DataFrame.from_dict(data_refined)\n",
    "anonymized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataframe containing the flattened data of anonymized_project.json\n",
    "anonymized_clean_df = pd.DataFrame(columns=['task_input', 'created_at', 'workpackage_total_size', 'loss',\n",
    "       'project_node_input_id', 'project_node_output_id', 'task_output',\n",
    "       'user', 'root_input', 'project_root_node_input_id', 'id', 'gui_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to extract data from each row\n",
    "def func(row):\n",
    "  global anonymized_clean_df\n",
    "  results = row.results['results']\n",
    "  results_df = pd.DataFrame.from_dict(results)\n",
    "  results_df['id'] = row.name\n",
    "  results_df['gui_type'] = row.gui_type\n",
    "  anonymized_clean_df = anonymized_clean_df.append(results_df.reset_index(drop=True))\n",
    "  anonymized_clean_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the function to anonymized dataframe\n",
    "anonymized_df.apply(func,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anonymized_clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract data from dictionaries in columns \"user\" and \"task_output\" then rename columns\n",
    "anonymized_clean_df = anonymized_clean_df.join(pd.DataFrame(anonymized_clean_df['user'].tolist())\n",
    "                                               .rename(columns={\"vendor_id\": \"user_vendor_id\", \"id\": \"user_id\",\n",
    "                                                                \"vendor_user_id\":\"user_vendor_user_id\"}))\n",
    "anonymized_clean_df = anonymized_clean_df.join(pd.DataFrame(anonymized_clean_df['task_output'].tolist()).\n",
    "                                               rename(columns={\"answer\": \"task_output_answer\",\n",
    "                                                               \"cant_solve\": \"task_output_cant_solve\",\n",
    "                                                               \"corrupt_data\":\"task_output_corrupt_data\",\n",
    "                                                               \"duration_ms\":\"task_output_duration_ms\"}))\n",
    "anonymized_clean_df.drop(['user','task_output'], axis = 1, inplace=True)\n",
    "anonymized_clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract image name\n",
    "anonymized_clean_df['image_name'] = anonymized_clean_df['root_input'].apply(lambda x: x.get('image_url')).str[-12:].str.strip('.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transpose the references dataframe\n",
    "references_df = references_df.transpose()\n",
    "references_df['image_name'] = references_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge both dataframes\n",
    "merged_df = anonymized_clean_df.merge(references_df, on='image_name')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### A ################################\n",
    "\n",
    "#Number of annotators contributed to the dataset\n",
    "merged_df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## B ##################################\n",
    "\n",
    "#get the duration statistics\n",
    "merged_df['task_output_duration_ms'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the duration has invalid values, so we remove any negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove any negative durations, then get the statistics\n",
    "merged_df = merged_df[merged_df['task_output_duration_ms'] > 0]\n",
    "merged_df['task_output_duration_ms'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# C ##################\n",
    "\n",
    "#group by user ID and count occurrences per user\n",
    "merged_df.groupby(['user_id']).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# D ################################\n",
    "\n",
    "\n",
    "#create a new column \"prediction\" to compare the user answer with the ground truth\n",
    "merged_df.loc[((merged_df['is_bicycle']==True) & (merged_df['task_output_answer']=='yes'))\n",
    "              |((merged_df['is_bicycle']==False) & (merged_df['task_output_answer']=='no'))\n",
    "              ,'prediction'] = 'correct'\n",
    "\n",
    "\n",
    "merged_df['prediction'].fillna('wrong',inplace=True)\n",
    "\n",
    "#for unsolvable tasks, the prediction is \"no_answer\"\n",
    "merged_df.loc[merged_df['task_output_cant_solve']==True,\"prediction\"] = \"no_answer\"\n",
    "\n",
    "#create column for image url\n",
    "merged_df['img_url'] = merged_df['task_input'].apply(lambda x: x.get('image_url'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by the image_url and the user answer, then count the number of yes or no\n",
    "task_answer_grouped = merged_df.groupby(['img_url','task_output_answer']).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get the highly disagreed images among the users\n",
    "task_answer_grouped['percentage'] = abs(task_answer_grouped['yes']-task_answer_grouped['no'])/10\n",
    "task_answer_grouped.sort_values(by=['percentage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for any corrupt data, the prediction is \"no_answer\"\n",
    "merged_df.loc[merged_df['task_output_corrupt_data']==True,\"prediction\"] = \"no_answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the percentage of can't solve tasks\n",
    "merged_df[merged_df.task_output_cant_solve == True].shape[0]/merged_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the percentage of corrupt data\n",
    "merged_df[merged_df.task_output_corrupt_data == True].shape[0]/merged_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"can't solve\" occurs with a percentage of 0.018% among the dataframe, while the \"corrupt data\" occur with a percentage of 0.0033%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unsolved tasks per user\n",
    "merged_df[(merged_df.task_output_corrupt_data == True) | (merged_df.task_output_cant_solve == True)].groupby('user_id').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by is_bicycle and count occurrences of each\n",
    "references_df.groupby('is_bicycle').count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the references values\n",
    "references_df.groupby('is_bicycle').count().reset_index().plot.bar(x='is_bicycle', y='image_name')\n",
    "plt.legend([\"count\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the reference set is balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by the user_id then prediction\n",
    "annotators_predictions = merged_df.groupby(['user_id','prediction']).size().unstack(fill_value=0)\n",
    "\n",
    "#calculate the accuracy for each annotator\n",
    "annotators_predictions['accuracy'] = annotators_predictions['correct']*100/(\n",
    "    annotators_predictions['correct']+annotators_predictions['wrong']+annotators_predictions['no_answer'])\n",
    "\n",
    "#sort the annotators by accuracy descending\n",
    "annotators_predictions.sort_values(by=['accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best annotator has an accuracy of 94.8%, the worst annotator has an accuracy of 88.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the annotators accuracy sorted descendingly\n",
    "annotators_predictions.reset_index().sort_values(by=['accuracy'], ascending=False).plot.bar(\n",
    "    x='user_id', y='accuracy');\n",
    "plt.ylim(80, 100);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
